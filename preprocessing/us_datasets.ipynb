{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0SWCE2E_trEO",
        "1gcwVYn2uPbz",
        "_pnwmLViubvR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing of US Datasets**"
      ],
      "metadata": {
        "id": "ashlDu65tS1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "prefix = '/content/drive'\n",
        "drive.mount(prefix, force_remount=True)"
      ],
      "metadata": {
        "id": "Itwtr-3dwA70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Walkability Data**"
      ],
      "metadata": {
        "id": "KJDDZJEnth--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Obtain data"
      ],
      "metadata": {
        "id": "yDYuWFVjx-DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk = pd.read_csv('/content/drive/My Drive/GoSQL_Project_Deliverables/Datasets/EPA_SmartLocationDatabase_V3_Jan_2021.csv')\n",
        "df_walk.head()"
      ],
      "metadata": {
        "id": "VUMRQJtttphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the data"
      ],
      "metadata": {
        "id": "xOmmY7SC07TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Later we will need a column 'CensusTract' to join with another dataset to determine zipcodes. Let's determine the 11 digit census tract number per the definition here:\n",
        "https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html"
      ],
      "metadata": {
        "id": "nx4TevFsZqh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk['CensusTract'] = (df_walk['STATEFP']*(10**9) + df_walk['COUNTYFP']*(10**6) + df_walk['TRACTCE'])\n",
        "df_walk.head()"
      ],
      "metadata": {
        "id": "W7xQGY5QYoXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 117 columns in the dataset...let's narrow that down to ones we are interested in\n",
        "columns_to_keep = ['CensusTract', 'NatWalkInd', 'TotPop', 'Ac_Total', 'Ac_Water', 'Ac_Land', 'Ac_Unpr', 'Workers', 'R_LowWageWk', 'R_MedWageWk', 'R_HiWageWk']\n",
        "df_walk = df_walk[columns_to_keep]\n",
        "df_walk.head()"
      ],
      "metadata": {
        "id": "gHkUBBDN1MFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main purporse of this dataset is to obtain a walkability index per zipcode. We will not accept tuples where 'NatWalkInd' is missing, however we will accept other columns with missing data as the EPA was able to calculate a walkability index for this location. Let's clean the data by removing any tuples where 'NatWalkInd' is missing or contains an illegal value (any value not between 1 and 20)."
      ],
      "metadata": {
        "id": "t1hJv7B_KAtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk['NatWalkInd'] = pd.to_numeric(df_walk['NatWalkInd'], errors='coerce') #convert natwalkInd to a float\n",
        "df_walk_clean = df_walk[((df_walk['NatWalkInd'].notna()) & (df_walk['NatWalkInd'] >= 1) & (df_walk['NatWalkInd'] <= 20))]"
      ],
      "metadata": {
        "id": "TWNSFbENLDup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimately our project aims to compare areas by zipcode, but currently df_walk associates collected data by census block group. Before further processing the EPA dataset, let's pull our zip tract data and join on Census tract to obtain a zipcode for each tuple."
      ],
      "metadata": {
        "id": "3Q2D-X4W2UK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_zip = pd.read_csv('/content/drive/My Drive/GoSQL_Project_Deliverables/Datasets/zip_tract.csv')\n",
        "# Ensure there are no duplicates\n",
        "print(df_zip.shape)\n",
        "df_zip = df_zip.drop_duplicates(subset=['CensusTract'])\n",
        "print(df_zip.shape)\n",
        "df_zip.head()"
      ],
      "metadata": {
        "id": "Bvuc-Z6Z7ABH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk_zips = pd.merge(df_walk_clean, df_zip, on='CensusTract', how='left')\n",
        "# Number of rows should stay the same, but number of columns should increase\n",
        "print(df_walk_zips.shape)\n",
        "print(df_walk_clean.shape)"
      ],
      "metadata": {
        "id": "IdKx6Y6natSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check to see if any zip code values were not found"
      ],
      "metadata": {
        "id": "Kn5ngnVXOvsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_zip_not_found = df_walk_zips[(df_walk_zips['Zip'].isna())]\n",
        "df_zip_not_found.shape"
      ],
      "metadata": {
        "id": "nIB12fNrcb8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if any zip codes are 6 digits or more. All should be 5."
      ],
      "metadata": {
        "id": "97jY9RuF8O7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_too_big = df_walk_zips[df_walk_zips['Zip'] > 99999]\n",
        "zip_too_big.shape # should have 0 rows"
      ],
      "metadata": {
        "id": "kyeP8ZKp8WU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "44,921 census tracts could not be aligned with a zip code. Drop all erroneous values and keep the remaining valid tuples (220,740 - 44,921 valid tuples)"
      ],
      "metadata": {
        "id": "Y-zS638hdi9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk_zips = df_walk_zips[(df_walk_zips['Zip'].notna())]\n",
        "df_walk_zips.shape # should have 220,740 - 44,921 rows"
      ],
      "metadata": {
        "id": "_urQBmFGd6Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregate data per zipcode. Most columns will require summation. NatWlkInd is an exception, we will take the average to get a walkability index representative of the zip code."
      ],
      "metadata": {
        "id": "0cs-Q68ffl61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk_zips.columns"
      ],
      "metadata": {
        "id": "W8bSiYnWkIIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_walk_zips = df_walk_zips[['Zip', 'NatWalkInd', 'TotPop', 'Ac_Total', 'Ac_Water',\n",
        "       'Ac_Land', 'Ac_Unpr', 'Workers', 'R_LowWageWk', 'R_MedWageWk',\n",
        "       'R_HiWageWk']] # drop unneeded columns\n",
        "aggregated_walk_zips = df_walk_zips.groupby('Zip').agg({\n",
        "    'NatWalkInd': 'mean',\n",
        "    'TotPop': 'sum',\n",
        "    'Ac_Total': 'sum',\n",
        "    'Ac_Water': 'sum',\n",
        "    'Ac_Land': 'sum',\n",
        "    'Ac_Unpr': 'sum',\n",
        "    'Workers': 'sum',\n",
        "    'R_LowWageWk': 'sum',\n",
        "    'R_MedWageWk': 'sum',\n",
        "    'R_HiWageWk': 'sum'\n",
        "}).reset_index()\n",
        "aggregated_walk_zips.head()"
      ],
      "metadata": {
        "id": "3s-eu_FSf8Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column representing the % of land protected from development (e.g. park, natural area or conservation area)\n",
        "aggregated_walk_zips['Ac_Prot'] = (aggregated_walk_zips['Ac_Land'] - aggregated_walk_zips['Ac_Unpr'])\n",
        "\n"
      ],
      "metadata": {
        "id": "5SaAJiHM3F8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename columns to use camel casing and match rest of database vars"
      ],
      "metadata": {
        "id": "KOtTU0ZfpcFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_walk_zips.rename(columns={'Ac_Total': 'AreaTotal',\n",
        "                                     'Ac_Land': 'AreaLand',\n",
        "                                     'Ac_Unpr': 'AreaUnpr',\n",
        "                                     'Ac_Water': 'AreaWater',\n",
        "                                     'Ac_Prot': 'AreaProt',\n",
        "                                     'Workers': 'CntWorkers',\n",
        "                                     'R_LowWageWk': 'CntLowWage',\n",
        "                                     'R_MedWageWk': 'CntMedWage',\n",
        "                                     'R_HiWageWk': 'CntHiWage',\n",
        "                                     }, inplace=True)\n",
        "aggregated_walk_zips.columns"
      ],
      "metadata": {
        "id": "cahKmRF0phwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prior to exporting let's convert zip to a 5 digit string, ensure null values are assigned default values, and negative numbers are assigned default values. No need to check NatWalkInd as we already dropped all invalid entries. No need to check Zip as we already removed all invalid entries."
      ],
      "metadata": {
        "id": "KfnrYAqk6vVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_walk_zips['Zip'] = aggregated_walk_zips['Zip'].astype(int).astype(str).str.zfill(5) ## change zip to a string and pad with zeros if necessary\n",
        "columns_to_mod = ['TotPop', 'AreaTotal', 'AreaWater', 'AreaLand',\n",
        "       'AreaUnpr', 'CntWorkers', 'CntLowWage', 'CntMedWage', 'CntHiWage',\n",
        "       'AreaProt']\n",
        "aggregated_walk_zips[columns_to_mod] = aggregated_walk_zips[columns_to_mod].fillna(0)\n",
        "aggregated_walk_zips[columns_to_mod] = aggregated_walk_zips[columns_to_mod].applymap(lambda x: 0 if x < 0 else x)\n",
        "aggregated_walk_zips.head()"
      ],
      "metadata": {
        "id": "igadRnPV6uRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export data"
      ],
      "metadata": {
        "id": "xI1eFrhFqOCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_walk_zips.to_csv('/content/drive/My Drive/GoSQL_Project_Deliverables/Datasets/us_walkability_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "xf0UPpolqP1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Life Expectancy Dataset**"
      ],
      "metadata": {
        "id": "0SWCE2E_trEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV files into DataFrames\n",
        "life_expectancy_df = pd.read_csv('/content/drive/MyDrive/CIS550/project/us/us_life_expectancy.csv', encoding='ISO-8859-1', dtype={'Census_Tract': str})\n",
        "fips_df = pd.read_csv('/content/drive/MyDrive/CIS550/project/us/fips-by-state.csv', encoding='ISO-8859-1', dtype={'fips': str})\n",
        "life_expectancy_df.head()"
      ],
      "metadata": {
        "id": "PJcut0YstzqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fips_df.head()"
      ],
      "metadata": {
        "id": "MvrDQpemAJjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the Census Tract columns are in a consistent format for joining\n",
        "life_expectancy_df['State'] = life_expectancy_df['State'].astype(str).str.strip()\n",
        "life_expectancy_df['County'] = life_expectancy_df['County'].astype(str).str.strip()\n",
        "fips_df['state'] = fips_df['state'].astype(str).str.strip()\n",
        "fips_df['county'] = fips_df['county'].astype(str).str.strip()"
      ],
      "metadata": {
        "id": "9GX5zbZj_yGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the DataFrames on the State and County columns\n",
        "merged_df = pd.merge(life_expectancy_df, fips_df, how='inner', left_on=['State', 'County'], right_on=['state', 'county'])\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "DhQ1R_XZDi0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the required columns\n",
        "final_df = merged_df[['fips', 'Census_Tract', 'Life Expectancy', 'Life Expectancy Range', 'Life Expectancy Standard Error', 'County', 'State']].copy()\n",
        "\n",
        "# Concatenate the fips and Census_Tract values to create a new column called CensusTract\n",
        "final_df.loc[:, 'CensusTract'] = final_df['fips'].astype(str) + final_df['Census_Tract'].astype(str)"
      ],
      "metadata": {
        "id": "cJ5LydqJDrnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the fips and Census_Tract columns\n",
        "final_df = final_df.drop(columns=['fips', 'Census_Tract'])\n",
        "\n",
        "# Filter the DataFrame to exclude rows where the state is 'ty'\n",
        "final_df = final_df[final_df['State'] != 'ty']"
      ],
      "metadata": {
        "id": "OSa7Cvl4ENel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the resulting DataFrame to a new CSV file\n",
        "final_df.to_csv('/content/drive/MyDrive/CIS550/project/us/us_life_expectancy_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "Oh6dn-7GEJbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_df = pd.read_csv('/content/drive/MyDrive/CIS550/project/us/zip_tract.csv', dtype={'CensusTract': str})\n",
        "zip_df.head()"
      ],
      "metadata": {
        "id": "q280V6IRFuVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_life_expectancy_df = pd.read_csv('/content/drive/MyDrive/CIS550/project/us/us_life_expectancy_cleaned.csv', dtype={'CensusTract': str})\n",
        "cleaned_life_expectancy_df.head()"
      ],
      "metadata": {
        "id": "D6o5BANaYGXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i need all the CensusTract in zip_df that are not in cleaned_life_expectancy_df. Deduplicate the CensusTracts. Then put these missing CensusTracts in a separate csv file\n",
        "\n",
        "missing_tracts = set(zip_df['CensusTract']) - set(cleaned_life_expectancy_df['CensusTract'])\n",
        "missing_tracts = list(missing_tracts)\n",
        "\n",
        "# Deduplicate the CensusTracts\n",
        "missing_tracts_df = pd.DataFrame({'CensusTract': missing_tracts})\n",
        "missing_tracts_df = missing_tracts_df.drop_duplicates()\n",
        "\n",
        "# Save the missing CensusTracts to a new CSV file\n",
        "missing_tracts_df.to_csv('/content/drive/MyDrive/CIS550/project/us/missing_tracts.csv', index=False)\n"
      ],
      "metadata": {
        "id": "nA064gQ6cp7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: please merge missing_tracts_df with cleaned_life_expectancy_df making sure that it is a left outer join with missing_tracts_df on the left. Merge on the CensusTract field which is a string\n",
        "\n",
        "all_tracts_life_expectancy_df = pd.merge(missing_tracts_df, cleaned_life_expectancy_df, how='outer', left_on='CensusTract', right_on='CensusTract')\n",
        "all_tracts_life_expectancy_df.head()"
      ],
      "metadata": {
        "id": "Z2B39I-HdYrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tracts_life_expectancy_df.to_csv('/content/drive/MyDrive/CIS550/project/us/all_tracts_life_expectancy.csv', index=False)"
      ],
      "metadata": {
        "id": "C7MIxdVBd2qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_life_expectancy_df = pd.read_csv('/content/drive/MyDrive/CIS550/project/us/all_tracts_life_expectancy.csv', dtype={'CensusTract': str})\n",
        "all_life_expectancy_df.head()"
      ],
      "metadata": {
        "id": "m5AvQcELk7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_zips_df = pd.read_csv('/content/drive/MyDrive/CIS550/project/us/zip_tract.csv', dtype={'CensusTract': str})\n",
        "all_zips_df.head()"
      ],
      "metadata": {
        "id": "l3iKZPkFlLOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Are there any values in CensusTract in all_zips_df that do not appear in the CensusTract column of all_life_expectancy_df. If so how many?\n",
        "\n",
        "missing_tracts = set(all_zips_df['CensusTract']) - set(all_life_expectancy_df['CensusTract'])\n",
        "num_missing_tracts = len(missing_tracts)\n",
        "\n",
        "print(f\"There are {num_missing_tracts} values in CensusTract in all_zips_df that do not appear in the CensusTract column of all_life_expectancy_df.\")\n"
      ],
      "metadata": {
        "id": "5XGPwW9UlTeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Income Dataset**"
      ],
      "metadata": {
        "id": "1gcwVYn2uPbz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJJ1Mbo0uLD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Housing Dataset**"
      ],
      "metadata": {
        "id": "Ihq0gqUSuQwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rent_fp = '/content/drive/MyDrive/CIS550/project/us/us_avg_rent_prices.csv'\n",
        "rent_df = pd.read_csv(rent_fp, dtype={'Zip': str})\n",
        "rent_df.head()"
      ],
      "metadata": {
        "id": "rwZZtyALuXzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_price_fp = '/content/drive/MyDrive/CIS550/project/us/us_avg_house_prices.csv'\n",
        "house_price_df = pd.read_csv(house_price_fp, dtype={'Zip': str})\n",
        "house_price_df.head()"
      ],
      "metadata": {
        "id": "_ZSmfSf2F7EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: For both house_price_df and rent_df if any value in the ZIP column isn't five characters long then it needs to be padded with zeros until it is five characters long. Also for the AvgPrice and AvgRent columns the values should only be to two decimal places. Remember that house_price_df has a AvgPrice column but not a AvgRent column and rent_df has a AvgRent column but not a AvgPrice column\n",
        "\n",
        "for df in [house_price_df, rent_df]:\n",
        "  df['Zip'] = df['Zip'].str.zfill(5)\n",
        "  if 'AvgPrice' in df.columns:\n",
        "    df['AvgPrice'] = df['AvgPrice'].apply(lambda x: round(x, 2))\n",
        "  if 'AvgRent' in df.columns:\n",
        "    df['AvgRent'] = df['AvgRent'].apply(lambda x: round(x, 2))\n"
      ],
      "metadata": {
        "id": "PyIqw94uGJG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rent_df.head()"
      ],
      "metadata": {
        "id": "7c0wN6TuHOpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_price_df.head()"
      ],
      "metadata": {
        "id": "LeO59zJxHTvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the house_price_df as a new csv file and save the rent_df as a new csv file\n",
        "\n",
        "house_price_df.to_csv('/content/drive/MyDrive/CIS550/project/us/us_avg_house_prices_cleaned.csv', index=False)\n",
        "rent_df.to_csv('/content/drive/MyDrive/CIS550/project/us/us_avg_rent_prices_cleaned.csv', index=False)\n"
      ],
      "metadata": {
        "id": "wFPweJePHV0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Air Quality Dataset**"
      ],
      "metadata": {
        "id": "_pnwmLViubvR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0kVYsz-ubBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}